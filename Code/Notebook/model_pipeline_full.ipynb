{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from termcolor import colored\n",
    "from pickle import dump\n",
    "\n",
    "from sklearn.preprocessing import Binarizer, OneHotEncoder, PowerTransformer, MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, ShuffleSplit, cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from yellowbrick.regressor import residuals_plot\n",
    "from yellowbrick.regressor import prediction_error\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the train data\n",
    "\n",
    "Since offline training is one time process, hence no special code was writing to grab data from folder. Also due to shortage of time. In future this process can also be automated so that training workflow can exceute more quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_excel_dff = pd.read_excel(r\"C:\\Users\\kumar\\OneDrive\\Desktop\\Akshat\\insurance\\Data\\Data 08-10-2021.xlsx\", engine='openpyxl')\n",
    "excel_dff = raw_excel_dff.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepratiion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Outlier Detection\n",
    "\n",
    "The Indentified outliers in columns __Incurred__ and __Capped Incurred__ with lower limit of 5th percentile and upper limit of 95th percentile is replaced with respective 5th and 95th percentile values respectively.\n",
    "This method will force variable towards a more normal disttribution and helps in reducing kurtosis as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(X, outlier_cutoff = 0.01):\n",
    "    \"\"\"\n",
    "    Impute the outliers with 5th and 95th percentile\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    outlier_cutoff : stope or start quantile range.range. default = 0.01\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    a dataframe without outliers\n",
    "\n",
    "    Note:\n",
    "    This function is setup for only \"Incurred\" and \"Capped Incurred\" columns. Since these two are only identified outlier columns during data exploration process\n",
    "    \"\"\"\n",
    "\n",
    "    outlier_columns = [\"Incurred\", \"Capped Incurred\"]\n",
    "    out_new_dff = X[X.columns.intersection(outlier_columns)].reset_index(drop=True)\n",
    "\n",
    "    out_new_dff.pipe(lambda x:x.clip(lower=x.quantile(outlier_cutoff), upper=x.quantile(1-outlier_cutoff), axis=1, inplace=True))\n",
    "\n",
    "    X.drop(outlier_columns, axis=1, inplace=True)\n",
    "    X = pd.merge(X, out_new_dff, left_index=True, right_index=True)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute outlier removal function for \"Incurred\" and \"Capped Incurred\" columns\n",
    "excel_dff = outlier_removal(excel_dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting Date Columns\n",
    "\n",
    "Date columns doesn't help in molde training process. Therefore, converting it into:\n",
    "- Year : Year of loss\n",
    "- Month : Month of loss\n",
    "- Weekend : If loss is on weekend\n",
    "\n",
    "Also, converted Inception to loss to Months since loss, to reduce range of column. Removed other non-useful columns identified during data exploration process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns for \"Date_of_loss\" column (Month, Weekend)\n",
    "excel_dff['Month'] = pd.DatetimeIndex(excel_dff['date_of_loss']).month\n",
    "excel_dff['Weekend'] = np.where((pd.to_datetime(excel_dff['date_of_loss']).dt.dayofweek) > 4, 1, 0)\n",
    "\n",
    "excel_dff['MSL'] = round(excel_dff['Inception_to_loss']/30, 0) # Months since loss\n",
    "\n",
    "excel_dff.drop([\"date_of_loss\",'Loss_code','Loss_description','TP_type_insd_pass_front', 'TP_type_pass_multi'], axis = 1, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Data\n",
    "\n",
    "Splitting training dataset into test and train before doing any futher preprocessing steps to data leakage.\n",
    "Split is performed using __StratifiedShuffleSplit__ so that training and test data represent similar distribution. Due to lack of data, the test set is 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data contains 7691 rows and 45 columns\n",
      "\n",
      "Traning data contains 6152 rows\n",
      "Test data contains 1539 rows\n"
     ]
    }
   ],
   "source": [
    "# Split Dataset for Training and Test set\n",
    "\n",
    "excel_dff[\"Incurred_cat\"] = pd.cut(excel_dff[\"Incurred\"],\n",
    "                             bins = [-np.inf, 0., 25027., 50055., 75082., np.inf],\n",
    "                             labels = range(1, 6))\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1234)\n",
    "for train_index, test_index in split.split(excel_dff, excel_dff[\"Incurred_cat\"]):\n",
    "    strat_train_set = excel_dff.loc[train_index].reset_index(drop=True)\n",
    "    strat_test_set = excel_dff.loc[test_index].reset_index(drop=True)\n",
    "\n",
    "print(f\"The original data contains {excel_dff.shape[0]} rows and {excel_dff.shape[1]} columns\")\n",
    "print(f\"\\nTraning data contains {strat_train_set.shape[0]} rows\")\n",
    "print(f\"Test data contains {strat_test_set.shape[0]} rows\")\n",
    "\n",
    "# Saving test data for future use\n",
    "strat_test_set.to_excel(r\"C:\\Users\\kumar\\OneDrive\\Desktop\\Akshat\\insurance\\Input\\Insurance.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Partition Train dataset to seprate features from target\n",
    "\n",
    "In below code cell, target __Incurred__ values are seperated from features input into seperate datasets. This is done to train regression model on features data and target \"Incurred\" (ground truths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = strat_train_set.drop(['Incurred', 'Claim Number', 'Incurred_cat'], axis = 1)\n",
    "target = strat_train_set['Incurred']\n",
    "\n",
    "# Drop ID Column and save it for future use\n",
    "id_col = strat_train_set['Claim Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering Pipeline\n",
    "\n",
    "All the columns created during data exploration task were added in pipeline after creating custom __DataframeFunctionTransformer__ class. Main advantage of creating this pipeline is to add it in final predictive pipeline and utilize it in future test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeFunctionTransformer():\n",
    "    \"\"\"\n",
    "    Pipeline class that can take only user defined function with fit and transform functionality\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : can take any user defined function and apply over pandas dataframe (required)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    a pandas dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "# ==================================================================================\n",
    "# Feature engineering function, new columns can be added or drop easily in pipeline\n",
    "# ==================================================================================\n",
    "def add_columns(X):\n",
    "    \"\"\"\"\n",
    "    Add featues to dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : a pandas dataframe\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    a pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    def flag_int(dff, col_list):\n",
    "        # This function add flag columns\n",
    "        binarizer = Binarizer(threshold=0, copy = True)\n",
    "\n",
    "        for columns in col_list:\n",
    "            dff[f'{columns}_flag'] =  binarizer.fit_transform(dff[columns].values.reshape(-1, 1))\n",
    "\n",
    "        return dff\n",
    "\n",
    "    tp_cols = [col for col in X if col.startswith('TP_')] # columns starting with \"TP_\" will be used for flag\n",
    "\n",
    "    X = flag_int(X, tp_cols) # passing list of \"TP_\" columns to flag function\n",
    "    \n",
    "\n",
    "    # ADD MORE COLUMNS IF REQUIRED\n",
    "\n",
    "    X['TP_injury_flag'] = np.where((X['TP_injury_whiplash'] > 0) | (X['TP_injury_traumatic'] > 0) | (X['TP_injury_fatality'] > 0) | (X['TP_injury_unclear'] > 0), 1, 0)\n",
    "    X['TP_insd_pass_injury'] = np.where((X['TP_type_insd_pass_back'] > 0) & (X['TP_injury_flag'] > 0), 1, 0)\n",
    "\n",
    "    X['Vehicle_mobile'] = np.where(X['Vehicle_mobile'].str.lower().isin(['n/k']) == True, 'missing', X['Vehicle_mobile'].str.lower())\n",
    "    X['PH_considered_TP_at_fault'] = np.where(X['PH_considered_TP_at_fault'].str.lower().isin(['n/k', '#']) == True, 'missing', X['PH_considered_TP_at_fault'].str.lower())\n",
    "    X['Location_of_incident'] = np.where(X['Location_of_incident'].str.lower().isin(['n/k', 'not applicable']) == True, 'missing', X['Location_of_incident'].str.lower())\n",
    "    X['Weather_conditions'] = np.where(X['Weather_conditions'].str.lower() == 'snow,ice,fog', 'chilly', X['Weather_conditions'].str.lower())\n",
    "    X['Weather_conditions'] = np.where(X['Weather_conditions'].isin(['n/a', 'n/k']) | X['Weather_conditions'].isnull() == True, 'missing', X['Weather_conditions'])\n",
    "\n",
    "\n",
    "    # numeric continuous columns conversion to float data type\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    int_list = X.select_dtypes(include=numerics).columns\n",
    "    int_cols = [col for col in X[int_list] if X[col].nunique() > 2]\n",
    "    int_cols =  [*int_cols, 'TP_type_cyclist', 'TP_type_pedestrian']\n",
    "\n",
    "\n",
    "    # Binary Flag columns conversion to int data type\n",
    "    int_flag = [col for col in X[int_list] if X[col].nunique() <= 2]\n",
    "    int_flag_remove = ['TP_type_cyclist', 'TP_type_pedestrian']\n",
    "    int_flag = list(set(int_flag) - set(int_flag_remove))\n",
    "\n",
    "\n",
    "    # Object columns conversion to category data type\n",
    "    cat_list = X.select_dtypes(exclude=numerics).columns\n",
    "    cat_cols = [col for col in X[cat_list]]\n",
    "\n",
    "    X[int_cols] = X[int_cols].apply(lambda x: x.astype('float64'))\n",
    "    X[int_flag] = X[int_flag].apply(lambda x: x.astype('int64'))\n",
    "    X[cat_cols] = X[cat_cols].apply(lambda x: x.astype('category'))\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Normalizer Pipeline\n",
    "\n",
    "This Pipeline is combination of:\n",
    "- Feature Engineering Pipeline -  Created in above step\n",
    "- Numeric Transformer - Numeric columns are first __normalized__ using __MinMaxScaler__ class of sklearn and then __standardized__ using __PowerTransformer__ class of sklearn with __yeo-johson__ method\n",
    "- Categorical Transformer - One Hot Encoding is used for categorical data since there aren't much unique categories for respective feature\n",
    "\n",
    "Lastly, all theree Pipelines are connected using __ColumnTransformer__ from sklearn with \"remainder = passthrough\" argument so that any untreated feature can also passthrough pipeline without dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used new column custom class for pipeline\n",
    "new_col_pipeline = Pipeline([\n",
    "    (\"NewColumns\", DataframeFunctionTransformer(add_columns))\n",
    "])\n",
    "\n",
    "# numeric column normalizer and standardizer pipeline\n",
    "scaler = MinMaxScaler()\n",
    "power = PowerTransformer(method='yeo-johnson', standardize = True)\n",
    "numeric_transformer = Pipeline(steps=[('MinMax', scaler), ('Power', power)])\n",
    "\n",
    "# categorical features standardizer pipeline\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# combining all three pipelines with Column Transformer\n",
    "column_preprocess = ColumnTransformer(remainder = \"passthrough\",\n",
    "    transformers = [\n",
    "    (\"NumScale\", numeric_transformer, selector(dtype_include = \"float64\")),\n",
    "    (\"CatTransformer\", categorical_transformer, selector(dtype_include = \"category\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Pipeline\n",
    "\n",
    "This is a final predictive pipeline which will be used to train algorithm on training dataset and predict on test dataset. This pipeline contains number of steps:\n",
    "- Feature Normalizer Pipeline - All feature engineering pipeline are combined in this, fist is \"new column\" and the \"feature scaling\"\n",
    "- PCA Pipeline - This is used for feature reduction, 47 components are used which explain 99% of variance in data\n",
    "- Regression Pipeline - XGBoost model is used with best parameters found during GridSearchCV (with 5 Cross Validations) at time of data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipe = Pipeline(steps=[\n",
    "    (\"NewColumns\", new_col_pipeline),\n",
    "    (\"ScaleColumns\", column_preprocess),\n",
    "    (\"pca\", PCA(n_components=0.99)),\n",
    "    (\"dt\", XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.6,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=0,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.03, max_delta_step=0, max_depth=10,\n",
    "             min_child_weight=10, monotone_constraints='()',\n",
    "             n_estimators=1000, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
    "             tree_method='gpu_hist', validate_parameters=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Feature Pipeline\n",
    "\n",
    "The traget feature which was forced normalized by removing outliers is standardized using __PowerTransformer__ class from sklearn with __yeo-johnson__ method. This will help in converging algorithm faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a {color: black;background-color: white;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a pre{padding: 0;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-toggleable {background-color: white;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-estimator:hover {background-color: #d4ebff;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-item {z-index: 1;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-parallel-item:only-child::after {width: 0;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-cde4c9e0-0fd8-4de0-aa76-6af73bace97a\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9002f32f-4772-49a1-bf47-0db096e78aa9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9002f32f-4772-49a1-bf47-0db096e78aa9\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('p', PowerTransformer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e21fac9e-3053-44c3-a1eb-07b9e318934c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e21fac9e-3053-44c3-a1eb-07b9e318934c\">PowerTransformer</label><div class=\"sk-toggleable__content\"><pre>PowerTransformer()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('p', PowerTransformer())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = PowerTransformer(method='yeo-johnson', standardize = True)\n",
    "target_pipeline = Pipeline(steps=[('p', power)])\n",
    "target_pipeline.fit(target.values.reshape(-1, 1)) # reshape target column since 1D array is required for Y_true parameter of algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Regression Pipeline\n",
    "\n",
    "The Pipeline created in step 2 is executed for features and target column from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:35:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-432cc612-be3e-4308-b3e2-7583eda643a6 {color: black;background-color: white;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 pre{padding: 0;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-toggleable {background-color: white;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-item {z-index: 1;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-parallel-item:only-child::after {width: 0;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-432cc612-be3e-4308-b3e2-7583eda643a6 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-432cc612-be3e-4308-b3e2-7583eda643a6\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e62fefdd-1db4-486c-b2a3-f1a34e423bbe\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e62fefdd-1db4-486c-b2a3-f1a34e423bbe\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('NewColumns',\n",
       "                 Pipeline(steps=[('NewColumns',\n",
       "                                  <__main__.DataframeFunctionTransformer object at 0x000001C680846B38>)])),\n",
       "                ('ScaleColumns',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('NumScale',\n",
       "                                                  Pipeline(steps=[('MinMax',\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  ('Power',\n",
       "                                                                   PowerTransformer())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object...\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='', learning_rate=0.03,\n",
       "                              max_delta_step=0, max_depth=10,\n",
       "                              min_child_weight=10, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=1000,\n",
       "                              n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              subsample=0.5, tree_method='gpu_hist',\n",
       "                              validate_parameters=1, verbose=1,\n",
       "                              verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"eb314842-51c1-4e2d-ba22-f5b7c55cd750\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"eb314842-51c1-4e2d-ba22-f5b7c55cd750\">NewColumns: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('NewColumns',\n",
       "                 <__main__.DataframeFunctionTransformer object at 0x000001C680846B38>)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"870bdb8c-520d-4c41-a0db-b24482b128c3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"870bdb8c-520d-4c41-a0db-b24482b128c3\">DataframeFunctionTransformer</label><div class=\"sk-toggleable__content\"><pre><__main__.DataframeFunctionTransformer object at 0x000001C680846B38></pre></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"458a5602-8696-4f79-a87f-2215e45d1754\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"458a5602-8696-4f79-a87f-2215e45d1754\">ScaleColumns: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('NumScale',\n",
       "                                 Pipeline(steps=[('MinMax', MinMaxScaler()),\n",
       "                                                 ('Power',\n",
       "                                                  PowerTransformer())]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000001C68031F128>),\n",
       "                                ('CatTransformer',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000001C680795898>)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cee6e3db-2569-4b6b-a71d-7827c3906e9b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"cee6e3db-2569-4b6b-a71d-7827c3906e9b\">NumScale</label><div class=\"sk-toggleable__content\"><pre><sklearn.compose._column_transformer.make_column_selector object at 0x000001C68031F128></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7c8152cc-69b9-4ed9-934c-2301af79dc29\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7c8152cc-69b9-4ed9-934c-2301af79dc29\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"dec09a1d-e1b7-4f41-8a4d-c5cf31e7d9c5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"dec09a1d-e1b7-4f41-8a4d-c5cf31e7d9c5\">PowerTransformer</label><div class=\"sk-toggleable__content\"><pre>PowerTransformer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fbea00a8-5de5-477e-b5e3-153a2830e062\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fbea00a8-5de5-477e-b5e3-153a2830e062\">CatTransformer</label><div class=\"sk-toggleable__content\"><pre><sklearn.compose._column_transformer.make_column_selector object at 0x000001C680795898></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"33339117-eead-42e3-8247-5388d0c33431\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"33339117-eead-42e3-8247-5388d0c33431\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"25e29c5c-a0c2-4e12-83c6-ce9ef8438f72\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"25e29c5c-a0c2-4e12-83c6-ce9ef8438f72\">remainder</label><div class=\"sk-toggleable__content\"><pre>['Vechile_registration_present', 'Incident_details_present', 'Injury_details_present', 'Weekend', 'TP_type_insd_pass_back_flag', 'TP_type_driver_flag', 'TP_type_pass_back_flag', 'TP_type_pass_front_flag', 'TP_type_bike_flag', 'TP_type_cyclist_flag', 'TP_type_pedestrian_flag', 'TP_type_other_flag', 'TP_type_nk_flag', 'TP_injury_whiplash_flag', 'TP_injury_traumatic_flag', 'TP_injury_fatality_flag', 'TP_injury_unclear_flag', 'TP_injury_nk_flag', 'TP_region_eastang_flag', 'TP_region_eastmid_flag', 'TP_region_london_flag', 'TP_region_north_flag', 'TP_region_northw_flag', 'TP_region_outerldn_flag', 'TP_region_scotland_flag', 'TP_region_southe_flag', 'TP_region_southw_flag', 'TP_region_wales_flag', 'TP_region_westmid_flag', 'TP_region_yorkshire_flag', 'TP_injury_flag', 'TP_insd_pass_injury', 'TP_type_insd_pass_back_flag_flag', 'TP_type_driver_flag_flag', 'TP_type_pass_back_flag_flag', 'TP_type_pass_front_flag_flag', 'TP_type_bike_flag_flag', 'TP_type_cyclist_flag_flag', 'TP_type_pedestrian_flag_flag', 'TP_type_other_flag_flag', 'TP_type_nk_flag_flag', 'TP_injury_whiplash_flag_flag', 'TP_injury_traumatic_flag_flag', 'TP_injury_fatality_flag_flag', 'TP_injury_unclear_flag_flag', 'TP_injury_nk_flag_flag', 'TP_region_eastang_flag_flag', 'TP_region_eastmid_flag_flag', 'TP_region_london_flag_flag', 'TP_region_north_flag_flag', 'TP_region_northw_flag_flag', 'TP_region_outerldn_flag_flag', 'TP_region_scotland_flag_flag', 'TP_region_southe_flag_flag', 'TP_region_southw_flag_flag', 'TP_region_wales_flag_flag', 'TP_region_westmid_flag_flag', 'TP_region_yorkshire_flag_flag', 'TP_injury_flag_flag', 'TP_insd_pass_injury_flag']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"79ea5c77-4e8b-4c19-8caa-086838a6d324\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"79ea5c77-4e8b-4c19-8caa-086838a6d324\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b9a5f417-3fea-4c7c-bd41-4525d13cdcac\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b9a5f417-3fea-4c7c-bd41-4525d13cdcac\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=0.99)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"62754614-0685-4e1b-abd6-0d470e5e8b05\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"62754614-0685-4e1b-abd6-0d470e5e8b05\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.6,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=0,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.03, max_delta_step=0, max_depth=10,\n",
       "             min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1000, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
       "             tree_method='gpu_hist', validate_parameters=1, verbose=1,\n",
       "             verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('NewColumns',\n",
       "                 Pipeline(steps=[('NewColumns',\n",
       "                                  <__main__.DataframeFunctionTransformer object at 0x000001C680846B38>)])),\n",
       "                ('ScaleColumns',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('NumScale',\n",
       "                                                  Pipeline(steps=[('MinMax',\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  ('Power',\n",
       "                                                                   PowerTransformer())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object...\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='', learning_rate=0.03,\n",
       "                              max_delta_step=0, max_depth=10,\n",
       "                              min_child_weight=10, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=1000,\n",
       "                              n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              subsample=0.5, tree_method='gpu_hist',\n",
       "                              validate_parameters=1, verbose=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipe.fit(features, target_pipeline.transform(target.values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = full_pipe.steps[2][1]\n",
    "n_pcs= model.components_.shape[0]\n",
    "initial_feature_names = features.columns\n",
    "most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "zipped_feats = zip(most_important_names, full_pipe.steps[3][1].feature_importances_)\n",
    "zipped_feats = sorted(zipped_feats, key=lambda x: x[1], reverse=True)\n",
    "features_col, importances = zip(*zipped_feats)\n",
    "top_features = features_col[:10]\n",
    "top_importances = importances[:10]\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(top_importances)), top_importances, color=\"b\", align=\"center\")\n",
    "plt.yticks(range(len(top_importances)), top_features)\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Predictive and Target Pipeline\n",
    "\n",
    "Both trained (__Regression__ and __Target__) pipelines are saved in pickle format for future use with new unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle Predictive Pipeline\n",
    "dump(full_pipe, open(\"model.pkl\", \"wb\"))\n",
    "\n",
    "# Pickle Target Pipeline\n",
    "dump(target_pipeline, open(\"target.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Prepration\n",
    "\n",
    "- Partition test data to seprate feature and target\n",
    "- Seprate ID column for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_testdata = strat_test_set.drop(['Incurred', 'Claim Number', 'Incurred_cat'], axis = 1)\n",
    "target_testdata = strat_test_set['Incurred']\n",
    "\n",
    "# Drop ID Column and save it for future use\n",
    "id_col_testdata = strat_test_set['Claim Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Trained Predictive Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = full_pipe.predict(features_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of Test Data: 2699.52\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.DataFrame(target_pipeline.inverse_transform(predictions_test.reshape(-1,1)), columns = [\"predictions\"])\n",
    "y_actuals = pd.DataFrame(target_testdata , columns = [\"actuals\"])\n",
    "\n",
    "data_comb = [y_pred, y_actuals]\n",
    "\n",
    "y_check = pd.concat([id_col_testdata, y_pred, target_testdata], axis = 1)\n",
    "\n",
    "mae = mean_absolute_error(target_pipeline.inverse_transform(predictions_test.reshape(-1,1)), target_testdata)\n",
    "print(f\"Mean Absolute Error of Test Data: {round(mae, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim Number</th>\n",
       "      <th>predictions</th>\n",
       "      <th>Incurred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6689</td>\n",
       "      <td>22.611</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2237</td>\n",
       "      <td>14798.183</td>\n",
       "      <td>9571.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1349</td>\n",
       "      <td>3826.262</td>\n",
       "      <td>2890.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1180</td>\n",
       "      <td>3086.135</td>\n",
       "      <td>3008.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7513</td>\n",
       "      <td>10.602</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5391</td>\n",
       "      <td>4.127</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3335</td>\n",
       "      <td>14.669</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3960</td>\n",
       "      <td>21001.740</td>\n",
       "      <td>65023.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1306</td>\n",
       "      <td>2940.443</td>\n",
       "      <td>2235.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6981</td>\n",
       "      <td>18.775</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1537</td>\n",
       "      <td>37566.215</td>\n",
       "      <td>38252.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7455</td>\n",
       "      <td>137.216</td>\n",
       "      <td>469.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7182</td>\n",
       "      <td>23469.426</td>\n",
       "      <td>39784.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>755</td>\n",
       "      <td>18878.713</td>\n",
       "      <td>20859.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3673</td>\n",
       "      <td>2477.953</td>\n",
       "      <td>2241.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4914</td>\n",
       "      <td>19130.346</td>\n",
       "      <td>14668.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2427</td>\n",
       "      <td>4.489</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1181</td>\n",
       "      <td>4643.222</td>\n",
       "      <td>4707.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1354</td>\n",
       "      <td>8504.921</td>\n",
       "      <td>8572.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6214</td>\n",
       "      <td>10950.959</td>\n",
       "      <td>6591.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>171</td>\n",
       "      <td>142.196</td>\n",
       "      <td>580.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4498</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>622</td>\n",
       "      <td>3465.154</td>\n",
       "      <td>3678.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6567</td>\n",
       "      <td>5081.177</td>\n",
       "      <td>4798.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4139</td>\n",
       "      <td>49.011</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2213</td>\n",
       "      <td>111.852</td>\n",
       "      <td>68.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7656</td>\n",
       "      <td>5551.409</td>\n",
       "      <td>6960.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2351</td>\n",
       "      <td>26863.809</td>\n",
       "      <td>24182.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7618</td>\n",
       "      <td>13.060</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>961</td>\n",
       "      <td>312.584</td>\n",
       "      <td>1299.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5089</td>\n",
       "      <td>2650.599</td>\n",
       "      <td>2751.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4317</td>\n",
       "      <td>19.284</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4920</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4736</td>\n",
       "      <td>946.696</td>\n",
       "      <td>1289.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5954</td>\n",
       "      <td>449.900</td>\n",
       "      <td>1476.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4038</td>\n",
       "      <td>11.547</td>\n",
       "      <td>23.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2639</td>\n",
       "      <td>3188.211</td>\n",
       "      <td>4006.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4273</td>\n",
       "      <td>57.255</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2972</td>\n",
       "      <td>22.630</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5966</td>\n",
       "      <td>3.960</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3615</td>\n",
       "      <td>131.303</td>\n",
       "      <td>724.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6499</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7327</td>\n",
       "      <td>17.667</td>\n",
       "      <td>260.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2905</td>\n",
       "      <td>287.102</td>\n",
       "      <td>711.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1986</td>\n",
       "      <td>47.689</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6625</td>\n",
       "      <td>24687.859</td>\n",
       "      <td>45531.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6527</td>\n",
       "      <td>29205.807</td>\n",
       "      <td>18425.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3936</td>\n",
       "      <td>46.156</td>\n",
       "      <td>427.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1154</td>\n",
       "      <td>61.333</td>\n",
       "      <td>82.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1110</td>\n",
       "      <td>800.392</td>\n",
       "      <td>1131.109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Claim Number  predictions  Incurred\n",
       "0           6689       22.611     0.000\n",
       "1           2237    14798.183  9571.048\n",
       "2           1349     3826.262  2890.385\n",
       "3           1180     3086.135  3008.016\n",
       "4           7513       10.602     0.000\n",
       "5           5391        4.127     0.000\n",
       "6           3335       14.669     0.000\n",
       "7           3960    21001.740 65023.748\n",
       "8           1306     2940.443  2235.702\n",
       "9           6981       18.775     0.000\n",
       "10          1537    37566.215 38252.543\n",
       "11          7455      137.216   469.503\n",
       "12          7182    23469.426 39784.121\n",
       "13           755    18878.713 20859.307\n",
       "14          3673     2477.953  2241.172\n",
       "15          4914    19130.346 14668.627\n",
       "16          2427        4.489     0.000\n",
       "17          1181     4643.222  4707.087\n",
       "18          1354     8504.921  8572.740\n",
       "19          6214    10950.959  6591.310\n",
       "20           171      142.196   580.995\n",
       "21          4498        0.365     0.000\n",
       "22           622     3465.154  3678.713\n",
       "23          6567     5081.177  4798.259\n",
       "24          4139       49.011     0.000\n",
       "25          2213      111.852    68.001\n",
       "26          7656     5551.409  6960.651\n",
       "27          2351    26863.809 24182.278\n",
       "28          7618       13.060     0.000\n",
       "29           961      312.584  1299.678\n",
       "30          5089     2650.599  2751.460\n",
       "31          4317       19.284     0.000\n",
       "32          4920        0.676     0.000\n",
       "33          4736      946.696  1289.860\n",
       "34          5954      449.900  1476.582\n",
       "35          4038       11.547    23.418\n",
       "36          2639     3188.211  4006.935\n",
       "37          4273       57.255     0.000\n",
       "38          2972       22.630     0.000\n",
       "39          5966        3.960     0.000\n",
       "40          3615      131.303   724.255\n",
       "41          6499        0.520     0.000\n",
       "42          7327       17.667   260.424\n",
       "43          2905      287.102   711.716\n",
       "44          1986       47.689     0.000\n",
       "45          6625    24687.859 45531.190\n",
       "46          6527    29205.807 18425.232\n",
       "47          3936       46.156   427.757\n",
       "48          1154       61.333    82.284\n",
       "49          1110      800.392  1131.109"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_check.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r\"C:\\Users\\kumar\\OneDrive\\Desktop\\Akshat\\insurance\\Output\"\n",
    "now = datetime.now()\n",
    "y_check.to_excel(str(output_path) + r\"/Incurance Ultimate Claim - Data Load \" + now.strftime(\"%d%B%y\") + \".xlsx\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdf069aa362895db6cbe367aabc30c6548f75770b60e1dcaf02dca4c1e5dd33e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('ins': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
